# EchoV1-emotional-ai
Echo V1 is an intelligent, emotion-aware AI assistant that takes voice or text input, detects your mood and intent, and responds empathetically using Groq's LLaMA-3 and natural-sounding speech. Built with Python, Streamlit, and modern AI APIs, it's your virtual emotional companion.

# EchoV1 Emotional AI ğŸ¤–ğŸ’

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://python.org)
[![Streamlit](https://img.shields.io/badge/streamlit-1.28%2B-red.svg)](https://streamlit.io)

> An intelligent, emotion-aware AI assistant that understands your mood and responds with empathy.

Echo V1 is your virtual emotional companion that takes voice or text input, detects your mood and intent, and responds empathetically using Groq's LLaMA-3 and natural-sounding speech synthesis. Built with modern AI APIs and a user-friendly Streamlit interface.

## âœ¨ Features

- **ğŸ¤ Voice Input**: Seamless speech-to-text conversion for natural interaction
- **ğŸ“ Text Input**: Traditional text-based communication support
- **ğŸ˜Š Emotion Detection**: Advanced mood and intent recognition from your input
- **ğŸ¤ Empathetic Responses**: Context-aware, emotionally intelligent replies
- **ğŸ”Š Natural Speech**: Text-to-speech with human-like voice synthesis
- **âš¡ Fast Processing**: Powered by Groq's high-performance LLaMA-3 model
- **ğŸ¨ User-Friendly UI**: Clean, intuitive Streamlit interface

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Voice/    â”‚â”€â”€â”€â–¶â”‚   Emotion   â”‚â”€â”€â”€â–¶â”‚    Groq     â”‚
â”‚  Text Input â”‚    â”‚  Detection  â”‚    â”‚  LLaMA-3    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   Speech    â”‚â—€â”€â”€â”€â”‚ Empathetic  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  Synthesis  â”‚    â”‚  Response   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8 or higher
- API keys for:
  - Groq API (for LLaMA-3)
  - Speech-to-text service
  - Text-to-speech service

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/mlwithharsh/EchoV1-emotional-ai.git
   cd EchoV1-emotional-ai
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up environment variables**
   ```bash
   cp .env.example .env
   # Edit .env with your API keys
   ```

4. **Run the application**
   ```bash
   streamlit run app.py
   ```

5. **Open your browser** and navigate to `http://localhost:8501`

## ğŸ”§ Configuration

Create a `.env` file in the root directory with the following variables:

```env
GROQ_API_KEY=your_groq_api_key_here
SPEECH_TO_TEXT_API_KEY=your_stt_api_key_here
TEXT_TO_SPEECH_API_KEY=your_tts_api_key_here
```

## ğŸ“– Usage

### Voice Interaction
1. Click the microphone button
2. Speak your message clearly
3. Echo V1 will process your emotion and respond accordingly
4. Listen to the empathetic audio response

### Text Interaction
1. Type your message in the text input field
2. Press Enter or click Send
3. Receive an emotionally aware text response
4. Optionally play the audio version

### Example Interactions

```
User: "I'm feeling really stressed about my exams tomorrow."
Echo V1: "I can hear the worry in your message. It's completely normal to feel stressed before important exams. Remember, you've prepared for this, and stress often means you care about doing well. Take some deep breaths, and trust in your preparation. You've got this! ğŸ’ª"

User: "I just got a promotion at work!"
Echo V1: "That's absolutely wonderful news! ğŸ‰ I can feel your excitement, and you should be incredibly proud of this achievement. Your hard work has clearly paid off. How are you planning to celebrate this milestone?"
```

## ğŸ› ï¸ Development

### Project Structure

EchoV1-emotional-ai/
â”œâ”€â”€ app.py                    # Main Streamlit application
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ .env.example             # Environment variables template
â”œâ”€â”€ echoV1/
â”‚   â”œâ”€â”€ Core_Brain/
â”‚   â”‚   â”œâ”€â”€ __init__.py      # Core brain initialization
â”‚   â”‚   â”œâ”€â”€ STT.py           # Speech-to-Text processing
â”‚   â”‚   â”œâ”€â”€ TTS.py           # Text-to-Speech synthesis
â”‚   â”‚   â”œâ”€â”€ memory_manager.py # Conversation memory management
â”‚   â”‚   â””â”€â”€ NLP_engine/
â”‚   â”‚       â”œâ”€â”€ __init__.py  # NLP engine initialization
â”‚   â”‚       â””â”€â”€ nlp_engine.py # Natural language processing logic
â”‚   â””â”€â”€ backend/
â”‚       â”œâ”€â”€ __init__.py      # Backend initialization
â”‚       â”œâ”€â”€ integration.py   # API integrations and orchestration
â”‚       â””â”€â”€ [other files]    # Additional backend components
â””â”€â”€ README.md

### Running Tests

```bash
pytest tests/
```

### Code Style

This project follows PEP 8 guidelines. Format your code using:

```bash
black .
flake8 .
```

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“Š Performance

- **Response Time**: < 2 seconds average
- **Emotion Accuracy**: 85%+ sentiment detection accuracy
- **Voice Quality**: Near-human natural speech synthesis
- **Scalability**: Supports concurrent users via Streamlit sharing

## ğŸ”® Roadmap

- [ ] Multi-language support
- [ ] Conversation memory and context retention
- [ ] Mobile app version
- [ ] Advanced emotion analytics dashboard
- [ ] Custom voice training
- [ ] Integration with popular messaging platforms

## ğŸ› Known Issues

- Voice input may have reduced accuracy in noisy environments
- API rate limits may apply depending on your service tier
- First response may take longer due to model loading

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [Groq](https://groq.com/) for providing fast LLaMA-3 inference
- [Streamlit](https://streamlit.io/) for the amazing web framework
- The open-source AI community for inspiration and support

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/mlwithharsh/EchoV1-emotional-ai/issues)
- **Discussions**: [GitHub Discussions](https://github.com/mlwithharsh/EchoV1-emotional-ai/discussions)
- **Email**: haresh2pandit@gmail.com

---

<div align="center">

**[â­ Star this project](https://github.com/mlwithharsh/EchoV1-emotional-ai)** if you find it helpful!

Made with â¤ï¸ by [mlwithharsh](https://github.com/mlwithharsh)

</div>
